# Modèle de détection de logiciels malveillants basé sur MLP

Un rapport pdf est accessible parmi les fichiers.

Warning: Only use this software according to your current legislation. Misuse of this software can raise legal and ethical issues which I don't support nor can be held responsible for.

# Introduction
Dans le monde numérique d'aujourd'hui, la sécurité des systèmes informatiques est devenue une préoccupation majeure. Les logiciels malveillants, qui sont des logiciels conçus pour causer des dommages à un système informatique, sont une menace constante. Pour lutter contre cette menace, nous avons développé un modèle d'apprentissage profond capable de détecter les logiciels malveillants en analysant les séquences d'appels d'API Windows dans les fichiers exécutables. L'objectif est de soumettre un fichier .exe à notre modèle et de recevoir en retour une prédiction indiquant si le fichier est un logiciel malveillant ou non. Ce rapport détaille la méthodologie utilisée, les résultats obtenus et les perspectives futures de ce projet.

# Dataset
La base de données que j'ai utilisée pour mon projet s'intitule "Malware Analysis Datasets: API Call Sequences", disponible sur Kaggle. Cette base de données contient des séquences d'appels API associées à différents échantillons de logiciels. Chaque échantillon est identifié par un hash unique, et les séquences d'appels API sont représentées par une série d'identifiants numériques (t0 à t99), chaque identifiant correspondant à un appel API spécifique.

![Presentation of the dataset](screenshots/rapport3.png)

# Etat de l'art de l'utilisation du Deep Learning pour la détection de logiciels malveillants
La détection de logiciels malveillants est un domaine de recherche en constante évolution, et l'utilisation du Deep Learning a montré des résultats prometteurs dans cette tâche. Les systèmes de détection de logiciels malveillants par Deep Learning exploitent la capacité des réseaux de neurones à apprendre des modèles complexes à partir de données brutes, ce qui leur permet de détecter efficacement les malwares en se basant sur des caractéristiques spécifiques.

Plusieurs approches de Deep Learning ont été explorées pour la détection de malwares, notamment les réseaux de neurones convolutifs (CNN), les réseaux de neurones récurrents (RNN), et les réseaux de neurones à propagation avant, tels que le Multi-Layer Perceptron (MLP). Chaque approche présente ses propres avantages et inconvénients en termes de représentation des données, de capacité de modélisation et de temps d'entraînement.

# Méthodologie

La première étape de notre projet a été de collecter et de préparer les données pour l'entraînement de notre modèle. Nous avons utilisé un ensemble de données disponible sur Kaggle, qui contient des séquences d'appels d'API pour différents logiciels malveillants et non malveillants. Les appels d'API sont des points d'entrée pour le système d'exploitation pour interagir avec le logiciel, et les séquences d'appels d'API peuvent donc fournir des informations précieuses sur le comportement du logiciel.

Après avoir nettoyé et prétraité les données, nous avons divisé l'ensemble de données en un ensemble d'entraînement et un ensemble de test. Cette division est essentielle pour évaluer la performance de notre modèle sur des données qu'il n'a jamais vues auparavant, ce qui nous donne une idée de sa capacité à généraliser à de nouvelles données.

Pour le modèle lui-même, nous avons choisi d'utiliser un perceptron multicouche (MLP), qui est un type de réseau de neurones artificiels. Le MLP est un modèle d'apprentissage profond, ce qui signifie qu'il est capable de modéliser des relations complexes et non linéaires entre les entrées et les sorties. Nous avons entraîné le MLP sur l'ensemble d'entraînement et l'avons testé sur l'ensemble de test.

# Modèle

L'ensemble des caractéristiques du modèle sont présentées dans le fichier malwaredetection.ipnyb.

# Résultats
Les résultats obtenus à partir de notre modèle MLP sont très prometteurs. Le modèle a obtenu un score d'entraînement de 99,67%. La matrice de confusion, qui est un tableau utilisé pour décrire les performances d'un modèle de classification, montre également que notre modèle est capable de distinguer avec précision les logiciels malveillants des non-malveillants.

# Interprétation des résultats
Bien que le modèle ait obtenu de très bons résultats sur l'ensemble de données de test, il est important de noter que ces résultats peuvent ne pas se généraliser à tous les fichiers .exe dans le monde réel. En effet, l'ensemble de données de test est une sous-partie de l'ensemble de données de formation, et il est donc possible que le modèle soit surajusté à cet ensemble de données spécifique. Cependant, ces résultats sont encourageants et indiquent que notre approche a le potentiel de détecter efficacement les logiciels malveillants. De plus, ils soulignent l'efficacité de l'apprentissage profond pour ce type de tâche de classification.

Matrice de confusion : Dans mon modèle de détection de logiciels malveillants, j'ai utilisé une matrice de confusion pour évaluer les performances. Voici ce que j'ai pu déduire de cette matrice :

Vrais positifs (TP) : Mon modèle a correctement identifié 138 logiciels malveillants. C'est encourageant, car cela signifie que le modèle est capable de détecter efficacement les malwares dans certains cas.

Faux positifs (FP) : Cependant, mon modèle a également prédit à tort que 113 fichiers sûrs étaient des malwares. C'est un domaine qui nécessite une amélioration, car ces erreurs pourraient entraîner des alertes inutiles pour l'utilisateur.

Faux négatifs (FN) : De plus, mon modèle a manqué 38 logiciels malveillants, les classant à tort comme sûrs. C'est un autre domaine d'amélioration important, car ces erreurs pourraient permettre à des malwares de passer inaperçus.

Vrais négatifs (TN) : D'un autre côté, mon modèle a correctement identifié 8487 fichiers sûrs. C'est un résultat très positif, car cela indique que le modèle est capable de reconnaître les fichiers sûrs avec précision.

![Matrice de confusion](screenshots/rapport4.png)



# Détection et détails sur detection.py

Une fois le modèle formé, nous avons développé un script Python, detection.py, pour permettre aux utilisateurs de soumettre des fichiers .exe pour analyse. Le script charge le modèle MLP formé, extrait les séquences d'appels d'API du fichier soumis, et utilise le modèle pour prédire si le fichier est un logiciel malveillant ou non. Les résultats de la prédiction sont ensuite affichés à l'utilisateur.

L'interface utilisateur est construite en utilisant la bibliothèque tkinter de Python, qui permet de créer des interfaces utilisateur graphiques. L'utilisateur peut soumettre un fichier en cliquant sur un bouton, et le résultat de la prédiction est affiché dans une étiquette.

`````
import tkinter as tk
from tkinter import filedialog
import joblib
import pefile
import os

# Charger le modèle à partir du fichier
model = joblib.load('malware-detection.pkl')
print("Le modèle est", model)
print(type(model))

# Fonction pour extraire les séquences d'appels API à partir d'un fichier exécutable
def extraire_sequences_appels_api(file_path):
    sequences_api = []
    try:
        pe = pefile.PE(file_path)  # Ouvrir le fichier exécutable avec pefile
        # Accéder aux sections pertinentes ou trouver les points d'entrée des DLL
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            for API in entry.imports:
                sequences_api.append(API.name)
        # Extraire les séquences d'appels API et les stocker dans sequences_api
    except pefile.PEFormatError:
        # Gérer les erreurs lors du traitement du fichier exécutable
        print("Erreur de format de fichier exécutable")
    return sequences_api

# Fonction pour soumettre le fichier exécutable et effectuer la prédiction
def soumettre_fichier():
    # Ouvrir une boîte de dialogue pour sélectionner le fichier exécutable
    file_path = filedialog.askopenfilename()
    
    # Traitement des données (assurez-vous de suivre le même traitement que lors de l'entraînement)
    sequences_api = extraire_sequences_appels_api(file_path)
    # Préparez les données d'entrée que vous souhaitez soumettre au modèle
    donnees_entree = [sequences_api]
    
    # Utiliser le modèle pour la prédiction
    prediction = model.predict(donnees_entree)
    
    # Afficher les résultats de la prédiction sur l'interface utilisateur
    if prediction == 'malware':
        result_label.config(text="Le fichier est détecté comme un malware.")
    else:
        result_label.config(text="Le fichier est détecté comme bon.")

# Créer l'interface utilisateur
root = tk.Tk()

# Bouton pour soumettre le fichier exécutable
submit_button = tk.Button(root, text="Soumettre un fichier", command=soumettre_fichier)
submit_button.pack()

# Étiquette pour afficher les résultats
result_label = tk.Label(root, text="")
result_label.pack()

# Lancer la boucle principale de l'interface utilisateur
root.mainloop()

`````

Voici ce que ça donne: 

![Presentation of the dataset](screenshots/rapport2.png)

# Test par un ransomware
Dans le cadre de notre test, nous avons utilisé un ransomware que nous avions développé lors d'un projet précédent. Le code source de ce ransomware est disponible sur mon compte GitHub : lien vers le repository.

Ce ransomware est conçu pour se camoufler en tant que fichier Excel, trompant ainsi la victime qui pourrait l'exécuter sans se rendre compte de sa nature malveillante

# Problèmes rencontrés

L'objectif était de pouvoir soumettre un fichier .exe et d'analyser ses séquences d'appels API afin de déterminer s'il s'agit ou non d'un malware. Malheureusement, les propriétaires de la base de données n'ont pas fourni les noms des séquences d'appels API correspondant aux numéros t1, ..., t99 qu'ils ont inclus dans leur base de données (par exemple VirtualAllocEx: 210). Cela nous empêche de convertir les séquences d'appels API en valeurs numériques, alors que notre modèle a été entraîné sur de telles données numériques. L'absence de ces informations essentielles rend impossible l'achèvement de ce système de détection.

C'est notamment ce qui est mentionné dans le rapport des chercheurs.








